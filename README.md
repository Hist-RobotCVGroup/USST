# USST
Image semantic segmentation has been widely applied in intelligent driving, aquatic species recognition, and marine exploration. However, underwater environments suffer from severe visual degradations such as water turbidity and light refraction, which significantly hinder segmentation performance. To address this issue, we propose a novel underwater semantic segmentation framework based on style transfer, termed USST.Specifically, an enhanced image stylization module is first introduced to augment training data by transferring visual styles while preserving semantic consistency across perturbations. A correlation map together with a semantic consistency loss is then designed to aggregate features with similar semantics and suppress ambiguities among different classes, improving the exploitation of semantic cues in underwater scenes. Furthermore, a pre-trained saliency generation module (UA-Vit) is incorporated before prediction to emphasize salient regions.Experiments on the SUIM and DeepFish datasets demonstrate that USST achieves 77.01\% and 96.53\% mIoU, respectively, outperforming state-of-the-art methods.
![语义分割效果图--透视图--small](https://github.com/user-attachments/assets/f857bfd2-1c52-4d40-b7d9-d41c935c89ee)
